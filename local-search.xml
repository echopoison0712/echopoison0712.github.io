<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Paxos算法推导</title>
    <link href="/2022/05/09/Paxos%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90/"/>
    <url>/2022/05/09/Paxos%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="Paxos算法解析"><a href="#Paxos算法解析" class="headerlink" title="Paxos算法解析"></a>Paxos算法解析</h1><p>本文是阅读自<a href="https://item.jd.com/12536538.html">《软件架构设计：大型网站技术架构与业务架构融合之道》</a> 这本书很喜欢，里面有很多干货，本文出自11.2小节</p><p>之前看<a href="(http://yuyangblog.cn/2019/09/25/Paxos%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/)">Paxos的证明</a>的时候，就是顺着P1、P2a、P2b、P2c的证明思路往下缕，整个证明过程看着欲仙欲死。而这次看的这个文章，是从一个实际的并发场景，引出Paxos要解决的问题，倒推要解决这个问题需要提供什么能力</p><h2 id="Paxos解决什么问题"><a href="#Paxos解决什么问题" class="headerlink" title="Paxos解决什么问题"></a>Paxos解决什么问题</h2><p>###1.什么是“时序”</p><p>如下图所示的三台机器组成的一个集群，集群内各节点之间互相通信且无leader节点。客户端向集群发送的三个请求分别被三个节点响应并传播。</p><p><img src="/blog-img/Paxos1.png"></p><p>假设每台机器都把收到的请求按日志存下来（这里的请求可以是客户端向服务端发送的请求，或者是服务端其他Node节点广播下来的请求）。当三个请求执行完毕后，只要三台机器的日志顺序是一样的，那么最终整个集群就是最终一致的集群，结果也就是正确的</p><p><img src="/blog-img/Paxos2.png"></p><p>通过这个简单的例子就能对“时序”有一个直观的了解：虽然三个客户端是并发的，没有先后顺序，但到了服务器的集群里必须保证三台机器的日志顺序是一样的，这就是所谓的“分布式一致性”。</p><h3 id="2-Paxos解决什么问题"><a href="#2-Paxos解决什么问题" class="headerlink" title="2.Paxos解决什么问题"></a>2.Paxos解决什么问题</h3><p>在例子中，Node1收到了X&#x3D;1之后，复制给Node2和Node3；Node2收到X&#x3D;3之后，复制给Node1和Node3；Node3收到X&#x3D;5之后，复制给Node1和Node2。客户端是并发的，三个Node之间的复制也是并发的，如何保证三个Node最终的日志顺序是一样的呢？这正是接下来要讲的Paxos要解决的问题！</p><h2 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h2><p>上文中，每个Node存储日志序列，Node之间保证日志序列完全一样即可。那么可能会有疑问，为啥存储日志，直接存储最终数据不好嘛？</p><p>（1）日志只有一种操作，就是append。而数据或状态一直在变化，可以add、delete、update。把三种操作转换成了一种，对于持久化存储来说简单了很多！（2）假如要做多机之间数据同步，如果直接同步状态，状态本身可能有一个很复杂的数据结构（比如关系数据库的关联表、树、图），并且状态也一直在变化，要保证多个机器数据一致，要做数据比对，就很麻烦；而如果同步日志，日志是一个一维的线性序列，要做数据比对，则非常容易！</p><p>状态机的原理是：一样的初始状态+一样的输入事件&#x3D;一样的最终状态。因此，要保证多个 Node 的状态完全一致，只要保证多个Node的日志流是一样的即可！即使这个Node宕机，只需重启和重放日志流，就能恢复之前的状态</p><p>因此，就回到了上文最后的问题：复制日志&#x3D;复制任何数据（复制任何状态机）。因为任何复杂的数据（状态机）都可以通过日志生成！</p><h2 id="一个朴素而深刻的思想"><a href="#一个朴素而深刻的思想" class="headerlink" title="一个朴素而深刻的思想"></a>一个朴素而深刻的思想</h2><p>当客户端发送3个请求的时候，上图所示的六种可能的序列都是对的，且同时我们分析了记录日志和记录最终的状态的优劣。因此需要找一个算法保证虽然客户端是并发的发送请求，但最终集群的Node之间记录的日志序列是相同的。</p><p>这里就提出了一个朴素的思想，即全世界对1，2，3……n的顺序的认知是相同的，包括人与机器。即2一定是插在1和3之间。</p><p>当集群任一Node收到X&#x3D;1的请求的时候，假设要把它存放到日志中的1号位置，在存放前都要询问集群剩余的机器是否可以把X&#x3D;1存放在各自的1号位置上，如果大家1号位置都空着那么就把X&#x3D;1存放在自己的1号位置上并周知集群节点也把X&#x3D;1存放在各自的1号位置上。</p><p>这里的关键思想就是，虽然每个Node接受到的请求不同，但大家对1号、2号、3号位置的认知是一样的，大家一起保证1号、2号、3号存储的数据一样即可。</p><p>这个例子中，每个Node在存储前，都要先询问一下其余Node，之后在得到肯定答复后再决定把这条日志写到哪个位置，<strong>这里有两个阶段，先问再决策，也就是Paxos 2PC的原型</strong>。</p><p>但这样有一个问题就是各个节点同时收到客户端的请求，在2PC的第一步询问时，1号位置都没有被实际占用呢，因此都准备把请求复制给其余节点，这就造成了冲突。还有另一个问题就是比如Node1询问Node2的1号位置是否空的时候Node2给了肯定答复，然后Node3再询问Node2的时候，Node2又同样给了肯定答复，这就导致Node1和Node3都得到了多数的认可并开始第二阶段。</p><p>Basic Paxos就是通过两个方法来解决这些问题。</p><p>第1，少数服从多数。Node1在填充1号位置时，发现1号位置的值被大多数人确定了，比如时X&#x3D;5（Node3占领了这个位置且Node2跟从了Node3），那么Node1就要接受这个事实把自己的1号位置也塞成X&#x3D;5。然后退而求其次去尝试占领2号位置，若2号位置也被占用则也要把它们的值塞进自己的2号位置去，再尝试看3号位置……</p><p>第2，当发现1号位置是空着的时候，就锁定这个位置不允许其余Node再占这个位置，除非它们的权利更大（怎么判断权利呢？没错，又回到上文的朴素思想，3&gt;2&gt;1）</p><p>如果发现1号位置为空，在提交的时候发现1号位置被其他Node占了，就会提交失败，重试，尝试第二个位置，第三个位置……所以，为了让1号位置日志一样，可能要重试好多次，每个节点都会不断重试2PC。这样不断重试2PC，直到最终各方达成一致的过程，就是Paxos协议执行的过程，也就是一个Paxosinstance，最终确定一个值。而 Multi Paxos 就是重复这个过程，确定一系列值，也就是日志中的每一条！</p><p>接下来将基于这种思想详细分析Paxos算法本身。</p><h4 id="Basic-Paxos算法"><a href="#Basic-Paxos算法" class="headerlink" title="Basic Paxos算法"></a>Basic Paxos算法</h4><p>在前面的场景中提到三个Client并发地向三个Node发送三条写指令。对应到Paxos协议，就是每个Node同时充当了两个角色：Proposer和Acceptor</p><p>（内心OS：😹，最开始顺着读的时候，只介绍了Proposer和Acceptor两个角色，虽然当时也介绍了说这俩角色可以是同一个人，但其实还是有点懵逼了，在这本书里却实打实的了解了）</p><p>当Node1收到Client1发送的X&#x3D;1的指令时，Node1就作为一个Proposer向所有的Acceptor （自己和其他两个Node）提议把X&#x3D;1日志写到三个Node上面。</p><p>下面详细阐述Paxos的算法细节。首先，每个Acceptor需要持久化三个变量（minProposalId，acceptProposalId，acceptValue）。在初始阶段：minProposalId&#x3D;acceptProposalId&#x3D;0，acceptValue&#x3D;null。然后，既然是2PC，那么自然算法有两个阶段：P1（Prepare阶段）和P2（Accept阶段）。</p><h5 id="1-P1-Prepare阶段"><a href="#1-P1-Prepare阶段" class="headerlink" title="1.P1(Prepare阶段)"></a>1.P1(Prepare阶段)</h5><p>P1a：Proposer广播prepare（n），其中n是本机生成的一个自增ID，不需要全局有序，比如可以用时间戳+IP。</p><p>P1b：Acceptor收到prepare（n）</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-keyword">if</span> n &gt; minProposalId,回复 <span class="hljs-literal">yes</span><br>更新 minProposalId = n(持久化)<br>返回(acceptProposalId,acceptValue)<br><span class="hljs-keyword">else</span> <br>回复 <span class="hljs-literal">no</span><br></code></pre></td></tr></table></figure><p>P1c：Proposer如果收到半数以上的yes，则取acceptorProposalId最大的acceptValue作为v，进入第二个阶段，即开始广播accept（n，v）。如果acceptor返回的都是null，则取自己的值作为v，进入第二个阶段！否则，n自增，重复P1a。</p><h5 id="2-P2-Accept阶段"><a href="#2-P2-Accept阶段" class="headerlink" title="2.P2(Accept阶段)"></a>2.P2(Accept阶段)</h5><p>P2a：Proposer广播accept（n，v）。这里的n就是P1阶段的n，v可能是自己的值，也可能是第1阶段的acceptValue。</p><p>P2b：Acceptor收到accept（n，v），做如下决策：</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-keyword">if</span> n &gt; minProposalId,回复 <span class="hljs-literal">yes</span><br>更新 minProposalId = acceptProposalId = n(持久化)<br>accpetValue = value<br><span class="hljs-keyword">return</span> minProposalId<br><span class="hljs-keyword">else</span> <br>回复 <span class="hljs-literal">no</span><br></code></pre></td></tr></table></figure><p>P2c：Proposer如果收到半数以上的yes，并且minProposalId&#x3D;n，则算法结束。否则，n自增，重复P1a。</p><h3 id="Multi-Paxos算法"><a href="#Multi-Paxos算法" class="headerlink" title="Multi Paxos算法"></a>Multi Paxos算法</h3><h4 id="1-活锁问题"><a href="#1-活锁问题" class="headerlink" title="1.活锁问题"></a>1.活锁问题</h4><p>在前面已经知道，Basic Paxos是一个不断循环的2PC。所以如果是多个客户端写多个机器，每个机器都是 Proposer，会导致并发冲突很高，也就是每个节点都可能执行多次循环才能确定一条日志。极端情况是每个节点都在无限循环地执行2PC，也就是所谓的“活锁问题”。</p><p>为了减少并发冲突，可以变多写为单写，选出一个Leader，只让Leader充当Proposer。其他机器收到写请求，都把写请求转发给Leader；或者让客户端把写请求都发给Leader。</p><blockquote><p>leader的选举方式可以自定义，可以简单的无脑取编号最大的节点做leader，leader节点周期的向别的节点发送心跳，比如周期是T，如果一个节点在2T内没有收到比自己编号更大的节点的心跳，那么自己变为leader。这个方案虽然可能造成脑裂问题，但反正Basic Paxos就是无leader的，所以这里及时短暂的出现了脑裂，但只是增大了并发冲突的概率，并不影响算法正确性</p></blockquote><h4 id="2-性能问题"><a href="#2-性能问题" class="headerlink" title="2. 性能问题"></a>2. 性能问题</h4><p>我们知道Basic Paxos是一个无限循环的2PC，一条日志的确认至少需要两个RTT+两次落盘（一次是 Prepare 的广播与回复，一次是 Accept 的广播与回复）</p><p>而Multi Paxos在选出Leader之后，它先广播一次Prepare，一旦超过半数同意，之后对于收到的每条日志直接执行Accept操作。在这里，Perpare不再是对一条日志的控制了，而是相对于拿到了整个日志的控制权。一旦这个Leader拿到了整个日志的控制权，后面就直接略过Prepare，直接执行Accept。从而可以把2PC优化成1PC，也就只需要一个RTT+一次落盘了。</p><p>如果有新的Leader出现怎么办呢？新的Leader肯定会先发起Prepare，导致minProposalId变大。这时旧的 Leader 的广播 Accept 肯定会失败，旧的 Leader 会自己转变成一个普通的Acceptor，新的Leader把旧的顶替掉了。</p><h4 id="3-被choose的日志，状态如何同步出去"><a href="#3-被choose的日志，状态如何同步出去" class="headerlink" title="3.被choose的日志，状态如何同步出去"></a>3.被choose的日志，状态如何同步出去</h4><p>对于Multi Paxos由于是Leader节点不断的广播Accept请求，那么对于一条日志，只有Proposer（也就是Leader） 接收到多数派对Accept请求的同意后，知道这条日志被“choose”了。而各个Accepotor只是被动的接受请求，只能说某个日志该Accept接受了但并不知道是否被集群接受。那么如何把这个信息传递给其他Accepotor。</p><h5 id="1-Proposer主动通知"><a href="#1-Proposer主动通知" class="headerlink" title="1. Proposer主动通知"></a>1. Proposer主动通知</h5><p>在accept原有的(n,v)基础上，再增加一个参数firstUnchooseIndex</p><p>Proposer在广播accept的时候，额外带来一个参数firstUnchosenIndex&#x3D;7。意思是7之前的日志都已经“choose”了。Acceptor收到这种请求后，检查7之前的日志，如果发现7之前的日志符合以下条件：acceptedProposal[i]&#x3D;&#x3D;request.proposal（也就是第一个参数n），说明1～6的日志都是来自这个Proposer广播的，leader未发生过切换，那么就把该日志的状态置为choose。</p><h5 id="2-Acceptor被动查询"><a href="#2-Acceptor被动查询" class="headerlink" title="2. Acceptor被动查询"></a>2. Acceptor被动查询</h5><p>当一个Acceptor被选为Leader后，对于所有未确认的日志，可以逐个再执行一遍Paxos，来判断该条日志被多数派确认的值是多少。比如还是刚才收到firstUnchosenIndex&#x3D;7的那个Acceptor，当他又收到7～9这三条日志后，被选为Leader，那么就对这3条日志逐个广播确认看看大家是否存储的事一致的</p><p>因为Basic Paxos有一个核心特性：一旦一个值被确定后，无论再执行多少遍Paxos，该值都不会改变！因此，再执行1遍Paxos，相当于向集群发起了一次查询！</p><p>至此，Multi Paxos算法就介绍完了。</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>Paxos</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Paxos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ConcurrentHashMap为什么使用synchronized而不用lock</title>
    <link href="/2019/10/15/ConcurrentHashMap%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8synchronized%E8%80%8C%E4%B8%8D%E7%94%A8lock/"/>
    <url>/2019/10/15/ConcurrentHashMap%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8synchronized%E8%80%8C%E4%B8%8D%E7%94%A8lock/</url>
    
    <content type="html"><![CDATA[<p>前段时间在面试快手的时候，遇到这样一个问题，JDK1.8之后ConcurrentHashMap为什么使用synchronized而不用lock。</p><span id="more"></span><h3 id="当时是怎么胡驺的"><a href="#当时是怎么胡驺的" class="headerlink" title="当时是怎么胡驺的"></a>当时是怎么胡驺的</h3><p>当时遇到这个问题是懵逼的，一阵头脑风暴之后瞎蒙了3个原因</p><ul><li><p>synchronized是Java的同步原语，可能性能上高过lock</p><blockquote><p>唯一还靠谱点的猜测，然而经简单测试貌似在高并发的情况下反而是lock的性能要优于synchronized</p></blockquote></li><li><p>ConcurrentHashMap出现的时候还没有lock，只能使用synchronized</p><blockquote><p>一看就是阅读源码不仔细，ReentrantLock的源码上已经注明了 @since 1.5</p></blockquote></li><li><p>lock是一个接口，从扩展性的角度来说不确定之后版本的实现类</p><blockquote><p>纯属瞎蒙</p></blockquote></li></ul><h3 id="书归正传"><a href="#书归正传" class="headerlink" title="书归正传"></a>书归正传</h3><p>面完之后在网上搜了一下没找到相关问题，于是只能继续展开头脑风暴并得出一个自认为还算靠谱点的结论</p><blockquote><p><strong>以下解释仅代表个人观点非官方，欢迎交流讨论，若各位大佬有权威的解释也欢迎直接拍过来</strong></p></blockquote><p>既然使用的是synchronized而不是lock，自然有其道理在里面，比较了一下二者的优缺点感觉synchronized唯一的优点可能就是代码简洁，不需要像lock一样去手动释放。如果只因为这一个原因的话Doug Lea大神会差这点代码量？</p><p>我们都知道1.8之后ConcurrentHashMap是通过锁Node数组的头节点来缩小并发的粒度，如果说<u>真的用lock来替换的话需要怎么做呢？</u>这个问题粗看起来好像不是一个问题，当时面试的时候也是下意识的就避过了这个问题直到今天认真思考一番后发现，如果真的用lock实现好像很”麻烦“</p><p>首先，我们说默认的ReentrantLock，它的使用方式是通过lock.lock()来访问并发代码块，它没有lock.lock(param)这样的方法来锁定某个参数，既然如此先不管怎么实现，它的实现方式肯定就没有synchronized(f){}这样来的简洁。</p><p>其次，先不管简不简洁的问题，如果继续使用lock的话，这个lock要放到哪个类下呢？这里自然而然先想到是放在ConcurrentHashMap类里做为一个成员变量存在，如果真的这么做的话，锁的粒度还是一个Node节点吗？貌似常规使用的话这里锁住的是整个put()方法。</p><p>ok，那不放到ConcurrentHashMap下就只能放到Node节点中去了，事实上1.7版本的ConcurrentHashMap也正是这么做的，只不过它的实现方式是让Segment内部类去继承ReentrantLock</p><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Segment</span>&lt;K,V&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title class_">ReentrantLock</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Serializable</span> &#123;<br><br>    <span class="hljs-comment">//尝试获取锁的最多尝试次数，即自旋次数</span><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">MAX_SCAN_RETRIES</span> <span class="hljs-operator">=</span><br>            Runtime.getRuntime().availableProcessors() &gt; <span class="hljs-number">1</span> ? <span class="hljs-number">64</span> : <span class="hljs-number">1</span>;<br><br>    <span class="hljs-comment">//HashEntry数组，也就是键值对数组</span><br>    <span class="hljs-keyword">transient</span> <span class="hljs-keyword">volatile</span> HashEntry&lt;K, V&gt;[] table;<br>    <span class="hljs-comment">//元素的个数</span><br>    <span class="hljs-keyword">transient</span> <span class="hljs-type">int</span> count;<br>    <span class="hljs-comment">//segment中发生改变元素的操作的次数，如put/remove</span><br>    <span class="hljs-keyword">transient</span> <span class="hljs-type">int</span> modCount;<br>    <span class="hljs-comment">//当table大小超过阈值时,对table进行扩容,值为capacity *loadFactor</span><br>    <span class="hljs-keyword">transient</span> <span class="hljs-type">int</span> threshold;<br>    <span class="hljs-comment">//加载因子</span><br>    <span class="hljs-keyword">final</span> <span class="hljs-type">float</span> loadFactor;<br><br>    Segment(<span class="hljs-type">float</span> lf, <span class="hljs-type">int</span> threshold, HashEntry&lt;K, V&gt;[] tab) &#123;<br>        <span class="hljs-built_in">this</span>.loadFactor = lf;<br>        <span class="hljs-built_in">this</span>.threshold = threshold;<br>        <span class="hljs-built_in">this</span>.table = tab;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>既然1.8通过Node[]替换了Segment，那么如果沿用lock的话就是要么让Node去继承ReentrantLock，或者干脆在Node中定义成员变量lock。</p><p>这个时候继续考虑1.8的锁逻辑，ConcurrentHashMap通过lock来锁住Node数组的头节点，既然锁的是头节点，那该头节点所在链的其余Node节点自然就不需要进行加锁控制，可是lock已然成为了Node的属性那么对于链上的其余节点来说，这个lock就是被浪费掉了，因为只有在头节点被remove掉的时候其余Node节点才有可能会用上该成员变量(即只有原头节点的next节点)。这中间编码方面来说还需要考虑锁的“交接”等问题。</p><p>其实最开始思考这个问题的时候想到的是下文扩展里的内容，但是分析不下去了换了个思维想到了上述原因。感觉扩展的部分可能也是原因之一但再往底层这两者对ConcurrentHashMap的影响分析不出来了，不知道有没有熟悉的小伙伴可以解答一二。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总结一下从编码角度来说，复杂度上升一个量级。又因为多引用了一个变量从资源角度来说会占用更多的资源。同时多引入的变量还是一个只针对头节点的一个变量。</p><p>以上，即是我对这个问题的思考。感觉很多“司空见惯”的场景仔细品一下还是有很多的乐趣在里面的</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>其实lock和synchronized除了网上说的是否公平、是否响应中断、是否支持绑定多个条件事件、是否需要手动释放锁资源外还有一个不同点。先说结论就是<strong>使用lock的时候线程处于waiting状态，而使用synchronized的时候处于blocked状态</strong></p><p>下面是分别使用lock和synchronized来实现的死锁demo</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">deadLockBySynchronized</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">Object</span> <span class="hljs-variable">o1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">Object</span> <span class="hljs-variable">o2</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">threadPool</span> <span class="hljs-operator">=</span> Executors.newFixedThreadPool(<span class="hljs-number">2</span>);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                <span class="hljs-keyword">synchronized</span> (o1)&#123;<br>                    System.out.println(<span class="hljs-string">&quot;synchronized===thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>                    <span class="hljs-keyword">try</span> &#123;<br>                        Thread.sleep(<span class="hljs-number">10</span>);<br>                    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                        e.printStackTrace();<br>                    &#125;<br>                    <span class="hljs-keyword">synchronized</span> (o2)&#123;<br>                        System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                <span class="hljs-keyword">synchronized</span> (o2)&#123;<br>                    System.out.println(<span class="hljs-string">&quot;synchronized===thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>                    <span class="hljs-keyword">try</span> &#123;<br>                        Thread.sleep(<span class="hljs-number">10</span>);<br>                    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                        e.printStackTrace();<br>                    &#125;<br>                    <span class="hljs-keyword">synchronized</span> (o1)&#123;<br>                        System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;);<br>        threadPool.shutdown();<br>    &#125;<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">deadLockByLock</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">Lock</span> <span class="hljs-variable">lock1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ReentrantLock</span>();<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">Lock</span> <span class="hljs-variable">lock2</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ReentrantLock</span>();<br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">threadPool</span> <span class="hljs-operator">=</span> Executors.newFixedThreadPool(<span class="hljs-number">2</span>);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                lock1.lock();<br>                System.out.println(<span class="hljs-string">&quot;lock===thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>                <span class="hljs-keyword">try</span> &#123;<br>                    Thread.sleep(<span class="hljs-number">10</span>);<br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                    e.printStackTrace();<br>                &#125;<br>                lock2.lock();<br>                System.out.println(<span class="hljs-string">&quot;lock:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>            &#125;<br>        &#125;);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                lock2.lock();<br>                System.out.println(<span class="hljs-string">&quot;lock===thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>                <span class="hljs-keyword">try</span> &#123;<br>                    Thread.sleep(<span class="hljs-number">10</span>);<br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                    e.printStackTrace();<br>                &#125;<br>                lock1.lock();<br>                System.out.println(<span class="hljs-string">&quot;lock:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>            &#125;<br>        &#125;);<br>        threadPool.shutdown();<br>    &#125;<br></code></pre></td></tr></table></figure><p>main方法如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception&#123;<br>        deadLockBySynchronized();<br>        deadLockByLock();<br>&#125;<br></code></pre></td></tr></table></figure><p>既然是死锁其输出也没得啥悬念</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">synchronized</span>===thread:==Thread[pool-<span class="hljs-number">1</span>-thread-<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,main]拿到o1资源<br><span class="hljs-keyword">synchronized</span>===thread:==Thread[pool-<span class="hljs-number">1</span>-thread-<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,main]拿到o2资源<br>lock===thread:==Thread[pool-<span class="hljs-number">2</span>-thread-<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,main]拿到o1资源<br>lock===thread:==Thread[pool-<span class="hljs-number">2</span>-thread-<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,main]拿到o2资源<br></code></pre></td></tr></table></figure><p>这个时候通过jstack来分析当前堆栈信息会发现一个有意思的现象</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20191015231618681.png" alt="image-20191015231618681"></p><p>从图中可以清晰的看到，使用lock的时候线程处于waiting状态，而使用synchronized的时候处于blocked状态。至于二者的区别 <a href="https://www.baidu.com/s?wd=waiting%E5%92%8Cblocked&rsv_spt=1&rsv_iqid=0xf619fe30000cc429&issp=1&f=8&rsv_bp=1&rsv_idx=2&ie=utf-8&tn=baiduhome_pg&rsv_enter=1&rsv_dl=tb&rsv_sug3=19&rsv_sug1=11&rsv_sug7=101&rsv_t=8b092cYLwYi+LTLP1r5aUWhZ+UlYgwZXptTtWZ//HtbeKQTp4PipfgVlWUW0kBn15wlz&rsv_sug2=0&inputT=16059&rsv_sug4=19665">百度一下 你就知道</a></p><p>TODO 猜测alibaba的Arthas的thread -b命令不适配lock也是基于这样的原因，回头翻翻源码确认一下</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JUC</tag>
      
      <tag>学习心得</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>巧妙记住函数调用对应栈桢的出入栈</title>
    <link href="/2019/10/13/%E5%B7%A7%E5%A6%99%E8%AE%B0%E4%BD%8F%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E5%AF%B9%E5%BA%94%E6%A0%88%E6%A1%A2%E7%9A%84%E5%87%BA%E5%85%A5%E6%A0%88/"/>
    <url>/2019/10/13/%E5%B7%A7%E5%A6%99%E8%AE%B0%E4%BD%8F%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E5%AF%B9%E5%BA%94%E6%A0%88%E6%A1%A2%E7%9A%84%E5%87%BA%E5%85%A5%E6%A0%88/</url>
    
    <content type="html"><![CDATA[<p>在学习JVM的时候，都会记住这样几个概念：</p><ul><li>栈是线程私有的。</li><li>每个方法的调用对应着栈桢的入栈出栈。</li><li>每个栈帧包含局部变量表、操作数栈以及指向当前方法所属类的运行时常量池的引用。</li><li>局部变量是线程安全的</li></ul><p>这些概念都不难理解也不难记住，不过吧总觉得这些就是干巴巴的概念，背下来也就过去了。今天突然意识到其实在看到这些相关概念前，就已经见到他们的身影并受到其恩惠了。</p><span id="more"></span><p>平时都有debug程序，而debug模式下可以看到调用栈信息，最开始学习debug的时候当时带我的同事就跟我说在Frames这里是debug调用栈，蓝色选中的就是当前程序停留的位置，它往下依次是调用的方法信息。右侧Variables就可以看到当前的变量信息。当时觉得很神奇但现在想想，调用栈里的每一层不对应着一个栈桢，然后variables中的值就是对应栈桢中存储的元素。</p><p>下面用一段死锁的demo来验证一下</p><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DeadLock</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Object</span> <span class="hljs-variable">o1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">Object</span> <span class="hljs-variable">o2</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception&#123;<br>        <span class="hljs-type">ExecutorService</span> <span class="hljs-variable">threadPool</span> <span class="hljs-operator">=</span> Executors.newFixedThreadPool(<span class="hljs-number">2</span>);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                <span class="hljs-type">int</span> <span class="hljs-variable">variableA</span> <span class="hljs-operator">=</span> <span class="hljs-number">10</span>;<br>                <span class="hljs-keyword">synchronized</span> (o1)&#123;<br>                    System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>                    <span class="hljs-keyword">try</span> &#123;<br>                        Thread.sleep(<span class="hljs-number">10</span>);<br>                    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                        e.printStackTrace();<br>                    &#125;<br>                    <span class="hljs-keyword">synchronized</span> (o2)&#123;<br>                        System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;);<br>        threadPool.submit(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>              <span class="hljs-type">int</span> <span class="hljs-variable">variableA</span> <span class="hljs-operator">=</span> <span class="hljs-number">20</span>;<br>                <span class="hljs-keyword">synchronized</span> (o2)&#123;<br>                    System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o2资源&quot;</span>);<br>                    <span class="hljs-keyword">try</span> &#123;<br>                        Thread.sleep(<span class="hljs-number">10</span>);<br>                    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                        e.printStackTrace();<br>                    &#125;<br>                    <span class="hljs-keyword">synchronized</span> (o1)&#123;<br>                        System.out.println(<span class="hljs-string">&quot;thread:==&quot;</span>+Thread.currentThread()+<span class="hljs-string">&quot;拿到o1资源&quot;</span>);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;);<br>        threadPool.shutdown();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20191013171640070.png?Expires=1570961902&OSSAccessKeyId=TMP.hZXzMytWTxztDTudcngFASAtM2u3Kb1tKfqDnZdtLYHenHE5neDv1z9kHu9KCtiNKz4tcqqjJXNkbQmAXd4vZqnBTLJWhGJDdZTtvWnMFb5VUuu58gEDAKSpCTP5hW.tmp&Signature=kifpth4zS0gbUBRwer5g1vuttuA=" alt="image-20191013171602272"></p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20191013171602272.png?Expires=1570961887&OSSAccessKeyId=TMP.hZXzMytWTxztDTudcngFASAtM2u3Kb1tKfqDnZdtLYHenHE5neDv1z9kHu9KCtiNKz4tcqqjJXNkbQmAXd4vZqnBTLJWhGJDdZTtvWnMFb5VUuu58gEDAKSpCTP5hW.tmp&Signature=LlM2M5ANKVE2ufKf/LbQOBE6f2Q=" alt="image-20191013171640070"></p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>抖机灵</tag>
      
      <tag>栈桢</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paxos算法推导</title>
    <link href="/2019/09/25/Paxos%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/"/>
    <url>/2019/09/25/Paxos%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC/</url>
    
    <content type="html"><![CDATA[<p>阅读《从Paxos到Zookeeper分布式一致性原理与实践》一书中有关Paxos一致性算法的部分，在此基础上增加一些个人的见解，试图讲得在大白话一点。</p><span id="more"></span><h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>首先参考维基百科的背景介绍</p><blockquote><p>分布式系统中的节点通信存在两种模型：<a href="https://zh.wikipedia.org/wiki/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98">共享内存</a>（Shared memory）和<a href="https://zh.wikipedia.org/wiki/%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92">消息传递</a>（Messages passing）。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础 Paxos 场景中，先不考虑可能出现消息篡改即<a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">拜占庭错误</a>的情况。Paxos 算法解决的问题是在一个可能发生上述异常的<a href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97">分布式系统</a>中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的研究就没有停止过。</p><p>为描述Paxos算法，Lamport虚拟了一个叫做Paxos的<a href="https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%87%98%E5%9F%8E%E9%82%A6">希腊城邦</a>，这个岛按照议会民主制的政治模式制订法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员，议长或者传递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。但是这里假设没有<a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">拜占庭将军问题</a>（Byzantine failure，即虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息）；只要等待足够的时间，消息就会被传到。另外，Paxos岛上的议员是不会反对其他议员提出的决议的。</p><p>对应于分布式系统，议员对应于各个节点，制定的法律对应于系统的状态。各个节点需要进入一个一致的状态，例如在独立<a href="https://zh.wikipedia.org/wiki/Cache">Cache</a>的<a href="https://zh.wikipedia.org/w/index.php?title=%E5%AF%B9%E7%A7%B0%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8&action=edit&redlink=1">对称多处理器</a>系统中，各个处理器读内存的某个字节时，必须读到同样的一个值，否则系统就违背了一致性的要求。一致性要求对应于法律条文只能有一个版本。议员和服务员的不确定性对应于节点和消息传递通道的不可靠性。</p></blockquote><h3 id="一致性算法的重要属性"><a href="#一致性算法的重要属性" class="headerlink" title="一致性算法的重要属性"></a>一致性算法的重要属性</h3><h4 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h4><p>指哪些需要保证永远不会发生的事情</p><ul><li>只有被提出的提案才能被选定</li><li>只能有一个值被选定</li><li>如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个</li></ul><h3 id="活性"><a href="#活性" class="headerlink" title="活性"></a>活性</h3><p>指那些最终一定会发生的事情</p><h3 id="算法推导"><a href="#算法推导" class="headerlink" title="算法推导"></a>算法推导</h3><h4 id="奠定基调"><a href="#奠定基调" class="headerlink" title="奠定基调"></a>奠定基调</h4><p>我理解的证明，就类似于高中数学那样，已知，求证。而推导过程就是根据题目的已知和XX公式&#x2F;定理得到各种中间过程，继而得出求证。而Paxos的推导过程却不是这样，因此也造成了我最开始读的时候总觉得哪里怪怪的原因。因此，这里先简单的按照我的理解来进行一下代入。</p><p>首先，既然是推导，那么我们推导的结论是什么？</p><blockquote><p>Paxos算法是一致性算法，其解决的问题就是如何在一个可能发生机器宕机&#x2F;网络异常的分布式系统中，快速且正确地在集群内部对<strong>某个数据的值</strong>达成<strong>一致</strong>，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。</p></blockquote><p>ok，结论出来了就是证明Paxos算法是面对该问题的解决方案，那么条件呢？已知呢？不能什么都没有硬生生的去证明吧。这些条件&#x2F;已知书的作者并没有像传统证明题那样直截了当的告诉你，而是在文中通过<strong>“需求”</strong>这样的名词来给出。老板的需求是提给产品的，产品的需求是提给开发的，那Paxos的需求是提给谁的呢？先给出结论：Paxos的需求是给下文中提到的三种角色的。</p><p>本段总结起来就是，如果分布式系统中各个参与者按照Paxos的需求那样去工作，那么整个分布式系统的数据是一致的。那么接下来的推导过程就变成了</p><ol><li>需求都是什么？</li><li>需求是怎么保证一致性的？</li></ol><h4 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h4><p>在一致性算法中有三种参与角色，分别为proposer、acceptor和learner</p><ul><li><p>proposer：proposers 提出提案类似于生产&#x2F;消费模型中的生产者</p></li><li><p>acceptor：acceptor 收到提案后可以<strong>批准</strong>（accept）提案，若提案获得多数派（majority）的 acceptors 的批准，则称该提案被<strong>选定</strong>（chosen）</p></li><li><p>learner：learner 只能“学习”被选定的提案</p></li></ul><p>在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，仍然可以选出一个提案，那么就暗示了如下的需求（📒小本本：需求P1出来了，显然该需求是对acceptor的需求）</p><blockquote><p>P1:一个acceptor必须批准第一次收到的提案</p></blockquote><p>上面这个需求会引出一个新的问题，就是如果有多个提案被不同的proposer同时提出，可能会造成每个acceptor都批准到它的第一个提案，每个提案的权重都相同</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190924224318547.png" alt="image-20190924224318547"></p><p>显然这种场景下是无法选出一个唯一提案的，另外，即使只有两个提案被选出且acceptor的数量是奇数的，看起来很完美然而即使只有1个acceptor出错，都有可能导致无法确定该选择哪个提案，如下图</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190924224513680.png" alt="image-20190924224513680"></p><p>因此在P1点基础上，我们还需要根据少数服从多数原则增加一个限制条件就是说一个提案被选定需要半数以上的acceptor接受(感觉这个限制条件也算是一个需求，但是文中并没有单列出来所以也不好说)  ，而这个限定条件就暗示着说一个acceptor必须能够批准不止一个提案。同时也意味着说一个提案可以被多个acceptor接受，那么怎么来区分被多个acceptor接受的提案呢？比如可以用前缀来表示，而这里paxos算法采用的是一个全局的唯一编号来唯一标示一个<strong>被acceptor批准</strong>的提案，当一个具有某Value值的提案被半数以上的acceptor接受后，我们就认为这个提案被批准了。因为引入了编号的概念所以提案已经不是单纯的Value值了，而是变成了一个“【编号，Value】”来表示一个提案。 </p><p>根据上面讲到的内容，我们虽然允许多个提案被选定，但同时必须保证所有被选定的提案具有相同的Value，这是一个关于提案的Value的约定，结合提案的编号，该约定定义如下（📒小本本：需求P2出来了，那该需求是针对哪个角色提出的需求呢？大眼一瞅感觉好像都不是，因此下文会对P2进行泛化来找到该需求的具体角色）</p><blockquote><p>P2:如果编号为M0、Value值为V0的提案即[M0,V0]被选定了，那么所有比编号M0更高的且被选定的提案，其Value值也必须是V0</p></blockquote><p>因为提案的编号是全序的，因此P2就保证了只有一个Value被选定这个安全性的属性。同时一个提案即然要被选定，那么首先必须被至少一个acceptor批准（半数以上批准 &lt;&#x3D;&gt; 选定）因此可以通过如下条件来满足P2</p><blockquote><p>P2a:如果编号为M0、Value值为V0的提案即[M0,V0]被选定了，那么所有比编号M0更高的且被acceptor批准的提案，其Value值也必须是V0</p></blockquote><p>P2a相比于P2，使用“被acceptor批准”来取代“选定”，由于只有批准是选定的充分不必要条件，因此P2a也就是P2的充分不必要条件。</p><p>至此，P1保持不变。但是因为通信是异步的，因此一个提案可以在任意时刻被acceptor接受，出现下图的场景</p><p><img src="http://pwxc1xwdv.bkt.clouddn.com/image-20190925002422980.png" alt="image-20190925002422980"></p><p>proposer2发松V2，由于网络等原因在V2还未被批准的时候 proposer1发送V1，被acceptor2～5先后批准产生了【M1～M4，V1】的提案（详见P2上的粗体：被批准了才有编号）这个时候V2姗姗来迟被acceptor1接受了，根据P1的规则acceptor1必须批准收到的第一个提案，因此产生了M5，这里发现M5的编号&gt; M0~M4 且V2!&#x3D;V1，与P2a矛盾了，而我们又需要P1来保证提案被选定，因此说明对P2对泛化P2a泛化的还不够，因此继续泛化成如下</p><blockquote><p>P2b:如果一个提案[M0,V0]被选定后，那么之后任何proposer产生的编号更高的提案，其value值都为V0</p></blockquote><p>这里是有一点小懵逼的，因为上文说了编号是只有被批准了才有，怎么到P2b这里感觉变成了只要被产生就有编号？多读几次后我认为这里的本意是，任何proposer产生的提案其value值都为V0，提案如果因为网络等原因被丢掉没被批准，这种异常情况不会对算法产生影响，如果被acceptor批准后，那么就会产生编号且编号会大于已被选定的提案[M0,V0]的编号M0。那么自然P2b也就是对proposer的需求</p><p>因为一个提案只有被proposer提出才能被acceptor批准，继而才能被整个集群选定，因此P2b又成为了P2a的充分不必要条件，继而成为P2的充分不必要条件</p><p>但是P2b只是一个对proposer的需求，是一个理论模型难以提出实现手段，所以需要再进一步的去泛化P2b。</p><p>结合P2-P2a、P2a-P2b的泛化思想，这里需要找的就是一个需求P2c，使得当P2c满足时，P2b满足，即IF P2c THEN (if [M0,V0]被选定，任意Mn&gt;M0的提案其value为V0)。再翻译一下就是找寻一种需求使得proposer生产的提案是符合规定的提案。</p><p>现在假如说proposer提出一个[Mn,Vn]的提案，即然该提案可以被提出说明要么之前还未有提案被选定（否则大概率Vn !&#x3D; V0，违背P2b，这个时候Vn可以是任意值）；要么就是已经有[M0,V0]被选定了，而因为编号M0的提案被选定，被选定就意味着存在半数以上的acceptor集合C，C中的每一个元素都批准了该value并产生了M0～Mn-1的编号且这些编号对应的value都是V0，而集群的任意一个半数以上子集S都和C至少有一个交点，那么得出结论</p><p>当集群选定一个提案后，集群的任意半数以上子集S都至少有一个acceptor，其批准过一个编号为M0～Mn-1，value &#x3D; V0的提案。</p><p>这时，只需要令新提出的Vn等于所有批准的小于Mn的提案中编号最大的提案的value值即可，即P2c的描述如下</p><blockquote><p>P2c:对于任意的Mn和Vn，如果提案[Mn,Vn]被提出，那么肯定存在一个由半数以上的acceptor组成的集合S，满足以下两个条件中的任意一个</p><ul><li>S中不存在任何批准过编号小于Mn的提案的acceptor</li><li>选取S中所有acceptor批准的编号小于Mn的提案，其中编号最大的那个提案其value值是Vn</li></ul></blockquote><p>维基百科对其的解释如下：</p><blockquote><p>P2c:如果一个编号为n的提案具有value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于 n的任何提案，要么他们已经接受（accept）的所有编号小于 n 的提案中编号最大的那个提案具有 value v。</p></blockquote><p>关于P2c到P2b的推导，是采用<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%A6%E5%BD%92%E7%BA%B3%E6%B3%95">数学归纳法</a>证明</p><p>假设具有value v的提案m获得批准，当n&#x3D;m+1时，采用反证法，假如提案n不具有value v，而是具有value w，根据P2c，则存在一个多数派S1，要么他们中没有人接受过编号小于n的任何提案，要么他们已经接受的所有编号小于n的提案中编号最大的那个提案是value w。由于S1和通过提案m时的多数派C之间至少有一个公共的acceptor，所以以上两个条件都不成立，导出矛盾从而推翻假设，证明了提案n必须具有value v；</p><p>若（m+1）..（N-1）所有提案都具有value v，采用反证法，假如新提案N不具有value v，而是具有value w’,根据P2c，则存在一个多数派S2，要么他们没有接受过m..（N-1）中的任何提案，要么他们已经接受的所有编号小于N的提案中编号最大的那个提案是value w’。由于S2和通过m的多数派C之间至少有一个公共的acceptor，所以至少有一个acceptor曾经接受了m，从而也可以推出S2中已接受的所有编号小于n的提案中编号最大的那个提案的编号范围在m..（N-1）之间，而根据初始假设，m..（N-1）之间的所有提案都具有value v，所以S2中已接受的所有编号小于n的提案中编号最大的那个提案肯定具有value v，导出矛盾从而推翻新提案n不具有value v的假设。根据数学归纳法，我们证明了若满足P2c，则P2b一定满足。</p><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95">Paxos算法</a></p><p><a href="https://item.jd.com/11622772.html">从Paxos到Zookeeper</a></p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>Paxos</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Paxos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读书笔记|《深入理解kafka:核心设计与实现》</title>
    <link href="/2019/09/15/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%7C%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3kafka-%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/"/>
    <url>/2019/09/15/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%7C%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3kafka-%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/</url>
    
    <content type="html"><![CDATA[<p>本篇记录了<a href="https://item.jd.com/12489649.html">《深入理解kafka:核心设计与实现》</a>的小概念，算是读书笔记吧，还待不断补充ing</p><span id="more"></span><h3 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h3><ul><li>主题是一个逻辑上的概念，可以细分为多个分区</li><li>同一主题下的不同分区包含的消息是不同的</li><li>kafka中的分区可以分布在不同的服务器上</li><li>每条消息被发送到broker前，会根据分区规则选择存储到哪个具体的分区</li><li>同一分区的不同副本保存的是相同的消息，其中leader副本负责处理读写请求，follower副本<strong>只</strong>负责与leader副本进行消息同步</li><li>分区中的所有副本统称为AR，所有与leader副本一致的（包括leader）称为ISR，与leader副本之后<strong>过多</strong>的成为OSR，所以AR &#x3D; ISR + OSR</li><li>ISR与HW和LEO有关系 （LEO标识当前日志文件中下一条待写入消息的offset，分区ISR集合的每个副本都有一个ISR，ISR中最小的为HW）</li><li>消费者只能拉到HW之前的消息</li></ul><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><ul><li>发送消息主要有三种方式：发后即忘（fire-and-forget）、同步（sync）、异步（async）</li><li>kafkaProducer一般发生两种异常：<ul><li>可重试异常：NetworkException、LeaderNotAvaliableException、UnknowTopicOrPartitionException、NotEnoughReplicasException等<ul><li>对于可重试异常，如果配置了retries参数，那么只要在规定的重试次数内自行恢复了就不会抛出异常</li></ul></li><li>不可重试异常</li></ul></li><li>kafkaProducer —&gt; send() —&gt; intgerceptor() —&gt; serializer() —&gt; partitioner() —&gt; broker</li><li>如果key不为null，计算得到的分区号会是所有分区中的任意一个（对key进行hash运算，相同hash的入同一分区），如果key为null，那么计算得到的分区号仅为可用分区中的任意一个</li><li>kafkaProducer会在消息被应答之前或消息发送失败时调用拦截器，优先于用户设定的callback之前执行</li><li>生产者架构图<br><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190730115238065.png?Expires=1570934794&OSSAccessKeyId=TMP.hZXzMytWTxztDTudcngFASAtM2u3Kb1tKfqDnZdtLYHenHE5neDv1z9kHu9KCtiNKz4tcqqjJXNkbQmAXd4vZqnBTLJWhGJDdZTtvWnMFb5VUuu58gEDAKSpCTP5hW.tmp&Signature=d7N0lnM8ajjqyK9plV9I6ia2U8U=" alt="image-20190730115238065"><ul><li>整个生产者由两个线程（主线程和sender线程）执行</li><li>RecordAccumulator 主要用来缓存消息 以便 Sender 线程可以批量发送</li><li>主线程中发送过来的消息都会被迫加到 RecordAccumulator 的某个双端队列( Deque)中，<br>在 RecordAccumulator 的内部为每个分区都维护了 一 个双端队列，队列中的内容就是<br>ProducerBatch，即 Deque<ProducerBatch></li><li>Sender 从 RecordAccumulator 中 获取缓存的消息之后，会进 一 步将原本&lt;分区， Deque&lt;<br>ProducerBatch&gt;&gt;的保存形式转变成&lt;Node, List&lt; ProducerBatch&gt;的形式,Sender 还 会进一步封装成&lt;Node,Request&gt;的形式</li><li>请求在从 Sender 线程发往 Kafka 之前还会保存到 InFlightRequests 中，它的主要作用是缓存了已经发出去但还没有收到响应的请求,通过配置参数还可 以限制每个连接最多缓存的请求数</li></ul></li></ul><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><ul><li>消费者可以通过集合&#x2F;正则的方式订阅多个主题subscribe()<ul><li>如果通过正则订阅后，有人创建新的符合该正则的主题后，消费者也可以消费到这个新加入的主题</li></ul></li><li>消费者可以直接订阅某些主题的特定分区 assign()</li><li>kafka中的消费是基于拉模式。</li><li>poll()涉及到消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容</li><li>位移提交<ul><li>kafka默认的消费位移的提交方式是自动提交，这里的自动提交是定期提交</li><li>每次真正向服务端发起拉取请求之前都会检查是否可以进行提交，如果可以就会提交上次轮训的位移</li><li>手动提交可以细分为同步和异步提交，对应kafkaConsumer的commitSync()和commintAsync()</li></ul></li><li>指定位移消费seek() 方法只能重置消费者分配到的分区的消费位置</li><li>再均衡是指分区的所属权从一个消费者转移到另一个消费者的行为，为消费组具备高可用性和伸缩性提供保障，不过在再均衡发生期间，消费组内的消费者是无法读取消息的</li><li>通过再均衡监听器来监听事件，进行位移提交等操作</li><li>kafkaProducer是线程安全的，然后consumer是非线程安全的，在consumer中定义了acquire()方法，通过CAS来判断当前是否只有一个线程在操作</li><li>拉消息包含两种场景，follower副本做同步以及consumer的接收</li></ul><h3 id="分区和副本"><a href="#分区和副本" class="headerlink" title="分区和副本"></a>分区和副本</h3><ul><li>创建topic时可以通过replica-assignment 来手动指定分区副本的分配方案</li><li>分区副本分配<ul><li>生产者：为每条消息指定所要发往的分区</li><li>消费者：为消费者指定可以消费消息的分区</li><li>集群：在哪个broker上创建哪些分区的副本</li></ul></li><li>创建topic<ul><li>kafka-topics.sh</li><li>kafkaAdminClient</li><li>直接zk创建子节点</li></ul></li><li>目前kafka只支持增加分区数而不支持减少分区数</li><li>删除topic<ul><li>通过指定删除</li><li>直接在zk的删除路径下创建同名节点</li><li>删除zk节点及log</li></ul></li><li>优先副本是指在AR集合列表的第一个副本，理想情况下优先副本就是leader副本</li><li>分区平衡 通过一定的方式促使优先副本选举为leader副本</li><li>kafka不会将失效的分区副本自动的前一到集群中剩余的可用broker节点上</li><li>分区重分配一般发生在集群扩容、broker节点失效的场景下对分区进行迁移</li><li>分区重分配的本质在于数据复制</li><li>一味的增加分区可能会导致kafka崩溃，原因在于增加一个分区时会对应增加一个文件描述符，文件描述符可能会不够</li></ul><h3 id="日志存储"><a href="#日志存储" class="headerlink" title="日志存储"></a>日志存储</h3><ul><li>一个副本对应一个日志文件夹，文件夹下包含多个LogSegment包括.log、.index、 .timeindex等其他文件</li><li>向log中增加消息是顺序写入的，只有最后一个LogSegment才能知晓写入操作</li><li>每个LogSegment中的日志文件（.log结尾）都有对应的两个索引文件(.index和.timeindex)，每个LogSegement的命名都是根据基准偏移量（baseOffset，表示当前LogSegment的第一条消息的offset）命名的</li><li>Kafka实现的压缩方式是将多条消息一起进行压缩</li><li>Kafka中的索引文件以稀疏索引的方式构建消息的索引，通过MappedByteBuffer将索引文件映射阿斗内存中，以加快索引的查询速度</li><li>日志分段文件切分条件<ul><li>大小超过配置的值，默认&gt;1GB</li><li>最大时间戳与当前时间查超过配置的值，默认 &gt; 7天</li><li>两个索引文件的大小超过配置的值，默认 &gt; 10MB</li><li>追加的消息偏移量超过配置的值，默认 &gt; Integer.MAX_VALUE</li></ul></li><li>日志清理<ul><li>日志删除（默认）<ul><li>基于时间的保留策略 默认7天</li><li>基于日志大小的保留策略 默认1GB</li><li>基于日志起始偏移量的保留策略</li></ul></li><li>日志压缩<ul><li>会保留一个key的最新value值</li><li>如果一条消息的key部位null但value为null，此消息称为墓碑消息，日志清理线程会进行清理并保留一段时间</li></ul></li></ul></li><li>kafka高可用<ul><li>顺序写入</li><li>页缓存</li><li>零拷贝 依赖底层的sendfile()</li></ul></li></ul><h3 id="深入服务端"><a href="#深入服务端" class="headerlink" title="深入服务端"></a>深入服务端</h3><ul><li>kafka自定义了一组基于TCP的二进制协议</li><li>kafka基于时间轮的概念自定义实现了用于延时功能的定时器<ul><li>时间轮是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个 定时任务列表，该列表是一个环形的双向链表，链表的每一项是定时任务项，封装了真正的定时任务</li><li>当任务的到期时间超过了当前时间轮所表示的时间范畴时，会尝试添加到上层时间轮中</li></ul></li><li>ack &#x3D; -1 的情况下，leader副本默认等待30s时间接受follower副本的ack</li><li>延时操作创建之后会加入延时操作管理器来管理，每个延时操作管理器会配备一个定时器来做超时管理。延时操作需要支持外部事件的处罚，所以需要配备一个监听池来监听每个分区的外部事件</li><li>kafka集群会有多个broker，其中一个broker会被选举为控制器，负责管理整个集群的梭鱼哦分区和副本的状态</li><li>控制器选举依赖zk，成功竞选控制器的broker会在zk中创建&#x2F;controller这个临时节点</li><li>每个broker都会在内存中保存当前控制器的brokerid值，被标示为activeControllerId</li><li>zk中还会有一个持久的节点用来保存控制器发生变更的次数，每个和控制器交互的请求都会携带该值，如果请求的值小于内存中的值则认为请求时失效的。kafka通过controller_epoch来保证控制器的唯一性，进而保证相关操作的一致性</li><li>优雅关闭<ul><li>使用脚本关闭可能不奏效，原因是ps命令会限制输出字符数不得超过页大小PAGE_SIZE &#x3D; 4096</li><li>所以jps查看kafka的pid，然后使用kill -s TERM PID &#x2F; kill -15 PID </li><li>kafka服务入口程序中有一个名为kafka-shutdown-hock的关闭钩子</li></ul></li></ul><h3 id="深入客户端"><a href="#深入客户端" class="headerlink" title="深入客户端"></a>深入客户端</h3><ul><li>消费者分区分配策略<ul><li>RangeAssignor 按照消费者总数和分区总数进行整除得到跨度，然后将分区按照跨度进行平均分配</li><li>RoundRobinAssignor 轮询方式分配，如果同一组内消费者订阅的信息不同，分配的会不均匀</li><li>StickyAssignor </li><li>自定义</li></ul></li><li>旧版消费者客户端使用zk上配置监听器来监听消费者组和kafka集群的状态，此时触发再均衡操作时会导致羊群效应和脑裂效应</li><li>新版使用消费者协调器和组协调器来解决该问题</li><li>消息中间件的消息传输保障有3个层级<ul><li>at most once</li><li>at least once</li><li>Exactly once</li></ul></li><li>由于kafka多副本机制，及对于网络等异常的重试机制，因此这里kafka选用的是at least once</li><li>而对于消费者而言，at most once&#x2F;at least once 取决于拉取和提交的相对顺序</li><li>为了实现生产者的幂等性，kafka引入来PID和序列号，每个新的生产者实例在初始化的时候会被分配一个PID，对于每个PID，消息发送到的每一个分区都有对应的序列号</li><li>broker端会在内存中为每一对&lt;PID，分区&gt;维护一个序列号，对于收到的消息只有当消息的序列号 &#x3D; broker.序列号 + 1时才接受</li><li>因为序列号是分区上的概念，所以幂等性并不跨越多个分区运作。而事务可以弥补这个缺陷</li><li>对于典型的流式应用：消费Atopic——do something ——生产Btopic，通过transactionalId实现事务</li><li>从生产者角度来说，通过事务kafka可以保证跨生产者会话的消息幂等发送（对有相同transactionalId的新生产者实例被创建且工作时，旧的相同transcationalId将不再工作）及跨生产者会话的事务恢复</li><li>从消费者角度分析，出于以下原因，事务语义较弱<ul><li>采用日志压缩后，由于相同key的消息会覆盖导致某些消息被清理</li><li>消息被分布在同一分区的多个日志分段，老的分段又被删除</li><li>消费者可以通过seek()访问任意offset的消息</li></ul></li></ul><h3 id="可靠性探究、"><a href="#可靠性探究、" class="headerlink" title="可靠性探究、"></a>可靠性探究、</h3><ul><li>当follower副本将leader副本LEO之前的日志全部同步时，认为follower副本追上leader副本</li><li>follower副本更新自己HW的算法是比较当前的LEO与leader副本传送过来的HW的值，取最小</li><li>leader副本会根据follower副本传来的LEO的最小值作为自己的HW</li><li>以前版本kafka使用的是基于HW的同步机制，但这样会有数据不一致的问题，原因是HW同步有间隙即follower在更新自己的LEO后需要再一轮的请求才会更新自己的HW，follow副本的HW不能比leader副本的HW高</li><li>新版本引入leader epoch在需要截断数据的时候使用该值作为参考依据而不是以前的HW</li><li>生产者写入与消费者读取消息都是与leader副本交互的，从而实现一种主写主独的模型</li><li>kafka分区及副本的设计导致每个broker上的读写负载是一样的</li><li>读写分离的弊端<ul><li>数据不一致</li><li>延时</li></ul></li><li>常规日志同步机制（少数服从多数）的弊端就是如果容忍1个follower的失败需要保证至少3个副本</li><li>kafka采用的是ISR机制</li></ul>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
      <category>kafka</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kafka</tag>
      
      <tag>读书笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>轮子---ElasticSearch的Nested结果到实体的映射</title>
    <link href="/2019/09/13/%E8%BD%AE%E5%AD%90-ElasticSearch%E7%9A%84Nested%E7%BB%93%E6%9E%9C%E5%88%B0%E5%AE%9E%E4%BD%93%E7%9A%84%E6%98%A0%E5%B0%84/"/>
    <url>/2019/09/13/%E8%BD%AE%E5%AD%90-ElasticSearch%E7%9A%84Nested%E7%BB%93%E6%9E%9C%E5%88%B0%E5%AE%9E%E4%BD%93%E7%9A%84%E6%98%A0%E5%B0%84/</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>项目使用了ES来替换MySQL的查询，然而在ES的实体定义过程中，我们选择了一个索引多Nested的形式来存储数据，这样就带来了一个结果就是查询出来的ES结果被打散到各个Nested的集合中去了。同时为了降低改造的耦合度，和前端的接口定义并没有修改，这就需要将层级的ES结果再打散到扁平的实体中去。因为映射的字段不同，甚至于映射的层级也不同，BeanUtils#copyProperties()方法并不适用，同时由于我们虽然使用了Nested类型，但是Nested下的List中的元素最多只有一个(业务上可以限定住)。因此这里简单造了个轮子来实现该方法。</p><span id="more"></span><h3 id="实体VO"><a href="#实体VO" class="headerlink" title="实体VO"></a>实体VO</h3><p>如下是ES的model，其中的Student和Course都是Nested类型</p><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Document(indexName = &quot;index&quot;,type = &quot;type&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicDataResult</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Serializable</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">1L</span>;<br>    <span class="hljs-meta">@Field(type = FieldType.Nested)</span><br>    <span class="hljs-keyword">private</span> List&lt;Student&gt; student;<br>  <span class="hljs-meta">@Field(type = FieldType.Nested)</span><br>  <span class="hljs-keyword">private</span> List&lt;Course&gt; course;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Student</span>&#123;<br>  <span class="hljs-keyword">private</span> Integer id;<br>  <span class="hljs-keyword">private</span> Integer name;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Course</span>&#123;<br>  <span class="hljs-keyword">private</span> Integer id;<br>  <span class="hljs-keyword">private</span> Integer name;<br>&#125;<br></code></pre></td></tr></table></figure><p>那么其查询结果是形如下面的json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;student&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;echo&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;course&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;java&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>而我们正常和前端约定好的返回结果可能是这个样子</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;studentId&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;studentName&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;echo&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;courseId&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;courseName&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;java&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>显然，其对应的实体就是酱样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Info</span>&#123;<br><span class="hljs-keyword">private</span> Integer studentId;<br>  <span class="hljs-keyword">private</span> Integer courseId;<br>  <span class="hljs-keyword">private</span> String studentName;<br>  <span class="hljs-keyword">private</span> String courseName;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>参照BeanUtils#copyProperties()，以及Mybatis的ResultMap的实现方式，显然反射是一个很奈斯的选项。</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>首先，既然是不同名称的字段的对照规则，自然需要有一张对照表来告诉机器字段间的对照关系。这样的对照表很自然的就想到了map来存储。这里定义了一个抽象父类AbstractConvertRule</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AbstractConvertRule</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> Map&lt;String,String&gt; <span class="hljs-title function_">getConvertMap</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>又因为这里的需求是从ES的Nested结构到扁平实体，因此又定义了一个抽象父类ElasticNestedConvertRule来提供一些默认的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ElasticNestedConvertRule</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractConvertRule</span> &#123;<br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">getStudent</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Student.&quot;</span>;<br>    &#125;<br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">getCourse</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Course.&quot;</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>ok，下面就是最终的映射实体类了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * key-value的关系和BeanUtils#copyProperties是反着的，emmm，好像不太友好</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicDataToInfoRule</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">ElasticNestedConvertRule</span>&#123;<br>    <span class="hljs-comment">/** 转换规则，key是待转换的,value是es的*/</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Map&lt;String,String&gt; map = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>  <span class="hljs-comment">// 父类提供的默认实现</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">STUDENT</span> <span class="hljs-operator">=</span> getStudent();<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">COURSE</span> <span class="hljs-operator">=</span> getCourse();<br>  <span class="hljs-comment">// key值是Info的字段，value是常量+该常量的实体中的字段</span><br>    <span class="hljs-keyword">static</span> &#123;<br>        map.put(<span class="hljs-string">&quot;studentId&quot;</span>,STUDENT + <span class="hljs-string">&quot;id&quot;</span>);<br>        map.put(<span class="hljs-string">&quot;courseId&quot;</span>,COURSE + <span class="hljs-string">&quot;id&quot;</span>);<br>      map.put(<span class="hljs-string">&quot;studentName&quot;</span>,STUDENT + <span class="hljs-string">&quot;name&quot;</span>);<br>        map.put(<span class="hljs-string">&quot;courseName&quot;</span>,COURSE + <span class="hljs-string">&quot;name&quot;</span>);<br>    &#125;<br>  <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Map&lt;String,String&gt; <span class="hljs-title function_">getConvertMap</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> map;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>既然对照关系出来了，剩下的就是通过反射来将A实体中的值映射到B实体中去了，下面是转换的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 将es查询出得bean转换成新的VO对象</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> setBean 待转换的实体</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> getBean es查询的实体</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@param</span> convertData 转换规则，key是待转换的,value是es的</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">convertData</span><span class="hljs-params">(Object setBean, Object getBean, Map&lt;String,String&gt; convertData)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>    Field[] fields = setBean.getClass().getDeclaredFields();<br>    <span class="hljs-keyword">for</span> (Field field : fields) &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">fieldName</span> <span class="hljs-operator">=</span> field.getName();<br>        <span class="hljs-keyword">if</span>(convertData.containsKey(fieldName))&#123;<br>            <span class="hljs-type">Object</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>            String[] split = convertData.get(fieldName).split(<span class="hljs-string">&quot;\\.&quot;</span>);<br>            <span class="hljs-keyword">if</span>(split.length != <span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">InvalidPropertiesFormatException</span>(<span class="hljs-string">&quot;convertData中,key值为:&quot;</span>+fieldName+<span class="hljs-string">&quot;的value值不合法,请检查&quot;</span>);<br>            &#125;<br>            <span class="hljs-comment">// Step1:先从BaseDataResult中取得具体的Bean</span><br>            <span class="hljs-type">Object</span> <span class="hljs-variable">tableBean</span> <span class="hljs-operator">=</span> dynamicGet(getBean, StringUtils.toLowerCaseFirstOne(split[<span class="hljs-number">0</span>]));<br>            <span class="hljs-keyword">if</span>(tableBean <span class="hljs-keyword">instanceof</span> ArrayList)&#123;<br>                <span class="hljs-keyword">if</span>(((ArrayList) tableBean).isEmpty())&#123;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br>                List&lt;?&gt; list = castObjectToList(tableBean);<br>                <span class="hljs-type">Object</span> <span class="hljs-variable">fieldBean</span> <span class="hljs-operator">=</span> list.get(<span class="hljs-number">0</span>);<br>                <span class="hljs-comment">// Step2:根据Step1中取得的Bean和具体的字段取值</span><br>                value = dynamicGet(fieldBean,split[<span class="hljs-number">1</span>]);<br>            &#125;<span class="hljs-keyword">else</span> &#123;<br>                value = tableBean;<br>            &#125;<br>            <span class="hljs-comment">// Step3: 将第二步拿到的值塞入待转换的实体中</span><br>            dynamicSet(setBean,fieldName,value);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>下面列了一些#convertDate中用到的私有方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Object <span class="hljs-title function_">dynamicGet</span><span class="hljs-params">(Object obj,String propertyName)</span> <span class="hljs-keyword">throws</span> NoSuchFieldException,IllegalAccessException&#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-type">Field</span> <span class="hljs-variable">field</span> <span class="hljs-operator">=</span> obj.getClass().getDeclaredField(propertyName);<br>        field.setAccessible(<span class="hljs-literal">true</span>);<br>        <span class="hljs-keyword">return</span> field.get(obj);<br>    &#125; <span class="hljs-keyword">catch</span> (NoSuchFieldException e) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NoSuchFieldException</span>(String.format(<span class="hljs-string">&quot;实体:%s中不包含:%s字段，请检查对照规则&quot;</span>,obj,propertyName));<br>    &#125; <span class="hljs-keyword">catch</span> (IllegalAccessException e) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalAccessException</span>(String.format(<span class="hljs-string">&quot;实体:%s中%s字段的不可见,请检查&quot;</span>,obj,propertyName));<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 这里如果对照的实体类型不同可能需要进行特殊处理，如从Integer--&gt;Long,Boolean--&gt;Integer等</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dynamicSet</span><span class="hljs-params">(Object obj,String propertyName,Object value)</span> <span class="hljs-keyword">throws</span> NoSuchFieldException,IllegalAccessException&#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        <span class="hljs-type">Field</span> <span class="hljs-variable">field</span> <span class="hljs-operator">=</span> obj.getClass().getDeclaredField(propertyName);<br>        <span class="hljs-comment">// 待塞入的值是Long而value值是Integer类型</span><br>        <span class="hljs-keyword">if</span>(field.getType() == Long.class &amp;&amp; value <span class="hljs-keyword">instanceof</span> Integer)&#123;<br>            value = ((Integer) value).longValue();<br>        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(field.getType() == Integer.class &amp;&amp; value <span class="hljs-keyword">instanceof</span> Byte)&#123;<br>            value = ((Byte) value).intValue();<br>        &#125;<br>        field.setAccessible(<span class="hljs-literal">true</span>);<br>        field.set(obj,value);<br>    &#125; <span class="hljs-keyword">catch</span> (NoSuchFieldException e) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NoSuchFieldException</span>(String.format(<span class="hljs-string">&quot;实体:%s中不包含:%s字段，请检查对照规则&quot;</span>,obj,propertyName));<br>    &#125; <span class="hljs-keyword">catch</span> (IllegalAccessException e) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalAccessException</span>(String.format(<span class="hljs-string">&quot;实体:%s中%s字段的不可见,请检查&quot;</span>,obj,propertyName));<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> &lt;T <span class="hljs-keyword">extends</span> <span class="hljs-title class_">List</span>&lt;?&gt;&gt; T <span class="hljs-title function_">castObjectToList</span><span class="hljs-params">(Object obj)</span>&#123;<br>    <span class="hljs-keyword">return</span> (T) obj;<br>&#125;<br></code></pre></td></tr></table></figure><p>至此，工具类就算完工了，剩下的就是调用了，其调用方式就喝BeanUtils#copyProperties差不多了，只不过注意是参数反过来了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">BasicDataToInfoRule</span> <span class="hljs-variable">rule</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BasicDataToInfoRule</span>();<br>Map&lt;String,String&gt; convertMap = rule.getConvertMap();<br><span class="hljs-type">Info</span> <span class="hljs-variable">info</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Info</span>();<br>BaseConvert.convertData(info,basicDataResult,convertMap);<br></code></pre></td></tr></table></figure><h3 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h3><p>再之后的需求中，又遇到了将带下划线的实体映射到驼峰的实体中去，不过好在本次是从一个扁平的实体到另一个扁平的实体中，因此继承抽象规则AbstractConvertRule类覆盖其#getConvertMap</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">UnderLineToCamelRule</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">AbstractConvertRule</span>&#123;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Map&lt;String,String&gt; map = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>  <br>  <span class="hljs-keyword">static</span>&#123;<br>      map.put(<span class="hljs-string">&quot;s_id&quot;</span>,<span class="hljs-string">&quot;sid&quot;</span>);<br>      map.put(<span class="hljs-string">&quot;s_name&quot;</span>,<span class="hljs-string">&quot;sName&quot;</span>);<br>    &#125;<br>  <br>  <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Map&lt;String, String&gt; <span class="hljs-title function_">getConvertMap</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> map;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>而后在BaseConvert的工具类中增加了对扁平实体的对照方法#convertVO，因为不需要处理层级关系，代码简单很多</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">convertVO</span><span class="hljs-params">(Object setBean,Object getBean,Map&lt;String,String&gt; convertMap)</span> <span class="hljs-keyword">throws</span> Exception&#123;<br>    Field[] fields = setBean.getClass().getDeclaredFields();<br>    <span class="hljs-keyword">for</span> (Field field : fields) &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">fieldName</span> <span class="hljs-operator">=</span> field.getName();<br>        <span class="hljs-keyword">if</span>(convertMap.containsKey(fieldName)) &#123;<br>            <span class="hljs-type">Object</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> dynamicGet(getBean, convertMap.get(fieldName));<br>            dynamicSet(setBean,fieldName,value);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h3><ul><li>平时在实现一个工具类的过程中，最好提供足够优秀的可扩展性</li><li>良好设计模式的重要性</li></ul>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
      <category>ES</category>
      
    </categories>
    
    
    <tags>
      
      <tag>轮子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读书笔记|《Redis设计与实现》</title>
    <link href="/2019/09/11/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%7C%E3%80%8ARedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/"/>
    <url>/2019/09/11/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%7C%E3%80%8ARedis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E3%80%8B/</url>
    
    <content type="html"><![CDATA[<p><a href="http://redisbook.com/">《Redis设计与实现》</a> 读书笔记</p><span id="more"></span><h1 id="数据结构与对象"><a href="#数据结构与对象" class="headerlink" title="数据结构与对象"></a>数据结构与对象</h1><h3 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h3><ul><li><p>Redis里面，C字符串只会做字符串字面量用在一些无需对字符串值进行修改的地方</p></li><li><p>数据结构</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831000346835.png" alt="image-20190831000346835"></p></li><li><p>SDS与C字符串的区别</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831095736147.png" alt="image-20190831095736147"></p><ul><li><p>常数复杂度获取字符串长度</p><p>通过使用SDS而不是C字符串，Redis将获取字符串长度所需的复杂度从O(N)降低到O(1)；</p><p>设置和更新SDS长度的工作是由SDS的API在执行时自动完成的</p></li><li><p>杜绝缓冲区溢出</p><p>由于C字符串不记录自身长度，因此可能带来缓冲区的溢出，而SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性</p></li><li><p>减少修改字符串时带来的内存重分配次数</p><ul><li><p>问题：对于字符串拼接操作可能产生缓冲区溢出、对于字符串截断操作可能内存泄漏</p></li><li><p>SDS通过未使用空间接触了字符串长度和底层数组长度的关联</p></li><li><p>两种优化策略</p><ul><li><p>空间预分配</p><p>对SDS修改后长度小于1MB，则分配和len同样大小的未使用空间</p><p>对SDS修改后长度大于1MB，分配1MB</p></li><li><p>惰性空间释放</p><p>当SDS的API需要缩短SDS保存的字符串时，不利己使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节存储起来</p></li></ul></li></ul></li><li><p>二进制安全</p><p>C字符串由于以空字符来判断结尾，因此若存储的流中包含空字符，会导致数据丢失</p><p>所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据</p></li><li><p>兼容部分C的函数</p></li></ul></li></ul><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><ul><li><p>在listNode的基础上定义了list数据结构来更方便的操作链表</p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831101225871.png"/><p> <img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831101321784.png" alt="image-20190831101321784"></p></li></ul><h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><ul><li><p>数据结构</p><p>哈希表节点dictEntry —-&gt; 哈希表ditch —-&gt; 字典dict</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831102124452.png" alt="image-20190831102124452"></p></li></ul><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831102139083.png" alt="image-20190831102139083"></p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831102334582.png" alt="image-20190831102334582"></p><ul><li><p>ht属性是一个包含两个项的数组，一般情况下字典只使用ht[0]哈希表，ht[1]哈希表只会在ht[0]在rehash时使用</p></li><li><p>因为dictEntry节点组成的链表没有指向链表表尾的指针，所有出于速度考虑程序总是将新节点添加到链表的表头位置</p></li><li><p>rehash</p><ul><li><p>扩容，那么ht[1]的大小为第一个&gt;&#x3D;ht[0].used*2 的2^n；如5 * 2 &#x3D;10，则扩容后为16(2^4)</p></li><li><p>收缩，那么ht[1]的大小为第一个&gt;&#x3D;ht[0].used的2^n</p></li><li><p>情景</p><ul><li><p>没有执行bgsave&#x2F;bgrewriteaof且负载因子&gt;&#x3D;1</p></li><li><p>在执行bgsave&#x2F;bgrewriteaof且负载因子&gt;&#x3D;5</p></li><li><p>负载因子&lt;0.1时自动收缩</p></li><li><p>负载因子 &#x3D; 哈希表已保存节点数量 &#x2F; 哈希表大小</p><blockquote><p>即没有保存+哈希表满 &#x2F; 在保存+5倍满的时候执行</p></blockquote></li></ul></li><li><p>rehash是渐进式的</p><ul><li>为ht[1]分配空间</li><li>维持索引计数器变量 rehashidx并设置为0</li><li>CURD时，除了执行指定操作外，还会顺带将ht[0]在rehashidx索引上的所有键值对rehash到ht[1]上，并自增rehashidx</li><li>rehash完成后置rehashidx &#x3D; -1</li></ul></li></ul></li></ul><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><ul><li>TODO</li></ul><h3 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h3><p>整数集合是集合键的底层实现之一，当一个集合只包含整数值元素且集合的元素数量不多时，Redis会使用整数集合作为集合键的底层实现</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190831211338761.png" alt="image-20190831211338761"></p><ul><li><p>升级</p><p>新元素的类型比集合现有的所有类型都要长</p><ul><li>步骤<ul><li>根据新元素的类型扩展整数集合底层数组的空间大小，为新元素分配空间</li><li>按新元素的类型转换现有的所有元素并放置到正确的位置上</li><li>新元素添加(尾or头)</li></ul></li><li>优势<ul><li>提升灵活性：可以任意的将int16、int32等类型的整数添加到同一个集合中</li><li>节约内存：在灵活性的基础上，若存储的都是int16数据，初始化的时候不会默认初始化成int64，只有在需要升级的时候才会去占用更多内存</li><li>不支持降级</li></ul></li></ul></li></ul><h3 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h3><p>压缩列表是列表键和哈希键的底层实现之一</p><p>压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值</p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190902114748806.png" alt="image-20190902114748806"></p><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190902114825957.png" alt="image-20190902114825957"></p><ul><li><p>压缩列表的节点构成</p><ul><li>Previous_entry_length 记录了压缩列表中前一个节点的长度</li><li>encoding 记录了节点的content属性所保存的数据的类型及长度</li><li>content 保存节点的值</li></ul></li><li><p>压缩列表的连锁更新</p><p>由于previous_entry_length的长度为1字节&#x2F;5字节，所以在添加&#x2F;删除新节点的时候可能会触发连锁更新，连锁更新在最坏的情况下需要对压缩列表进行N次的空间重分配操作，但由于其造成的几率低（触发条件苛刻）因此默认不需要考虑</p></li></ul><h1 id="对象系统"><a href="#对象系统" class="headerlink" title="对象系统"></a>对象系统</h1><p>Redis根据SDS，双端链表，字典，压缩列表，整数集合等数据结构来创建对象系统</p><ul><li>使用对象的好处<ul><li>redis可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行给定的命令</li><li>在不同的使用场景，为对象设置多种不同的数据结构实现，优化对象在不同场景下的使用效率</li></ul></li></ul><p><img src="https://echopoison-blog.oss-cn-beijing.aliyuncs.com/image-20190902142057365.png" alt="image-20190902142057365"></p><p>当我们对一个数据库键执行TYPE命令时，返回的结果为数据库键对应的值对象的类型而非键对象的类型（键对象的类型就是字符串对象）</p><ul><li><p>type的取值从“REDIS_STRING”,”REDIS_LIST”,”REDIS_HASH”,”REDIS_SET”,”REDIS_ZSET”中取值</p></li><li><p>encoding的取值从long类型的整数、embstr编码的简单动态字符串、简单动态字符串、字典、双端链表、压缩列表、整数集合、跳表和字典取值</p><p>每种类型的对象都至少使用了两种不同的编码</p></li><li><p>字符串对象</p><ul><li>字符串对象的编码可以是int（整数）、raw（&gt;32字节的字符串）、embstr（&lt;32字节的字符串）</li><li>raw和embstr<ul><li>embstr是专门用来保存短字符串的一种优化编码方式，和raw一样都适用redisObject和sdshdr结构来表示字符串对象</li><li>raw会调用两次内存分配函数来创建redisObject结构和sdshdr结构而embstr编码则通过调用一次内存分配函数来创建一块连续的空间，空间中依次包含redisObject和sdshdr两个结构，而embstr编码则通过调用一次内存分配函数来分配一块联系的空间，空间中依次包含redisObject和sdshdr两个结构</li></ul></li><li>int编码和embstr编码的字符串对象在条件满足的情况下，会被转换为raw编码的字符串对象</li><li>因为没有对embstr编码的字符串对象编写所以embstr编码的字符串对象实际上是只读的，当对该对象执行修改命令时，程序会先将对象的编码从embstr转换成raw格式</li></ul></li><li><p>列表对象</p><ul><li>列表对象的编码可以是ziplist或者linkedlist</li><li>列表对象可以同时满足以下两个条件时使用zipList<ul><li>列表对象保存的所有字符串元素的长度都&lt;64字节</li><li>列表对象保存的元素数量少于512个</li></ul></li></ul></li><li><p>哈希对象</p><ul><li>哈希对象的编码可以是zipList或者hashtable</li><li>哈希对象使用ziplist编码的条件和列表对象相同</li></ul></li><li><p>集合对象</p><ul><li>集合对象的编码可以是intset或者hashtable</li><li>集合对象可以同时满足以下两个条件时使用intset<ul><li>集合对象保存的所有元素都是整数值</li><li>集合对象保存的元素数量不超过512个</li></ul></li></ul></li><li><p>有序集合对象</p><ul><li>有序集合对象的编码可以是ziplist或者skiplist</li></ul></li><li><p>类型检查与命令多态</p><p>原因就是redis操作键的命令分为针对任何类型的键如DEL、EXPIRE等和针对特定对象的键；同时又因为对同一对象的底层实现可以有多种情况</p></li><li><p>内存回收</p><p>Redis在自己的对象系统中构建了一个引用计数技术来直线内存回收机制</p></li><li><p>对象共享（类似于Java常量池）</p><ul><li>对象共享的步骤<ul><li>将数据库键的值指针指向一个现有的值对象</li><li>被共享的值对象的引用计数+1</li></ul></li><li>Redis会在初始化时会初始化1w个字符串对象（类型Integer的缓存）</li></ul></li></ul><h1 id="单机数据库的实现"><a href="#单机数据库的实现" class="headerlink" title="单机数据库的实现"></a>单机数据库的实现</h1><ul><li><p>数据库键空间</p><p>redis是一个键值对数据库服务器，服务器的每个数据库都由一个redis.h&#x2F;redisDb结构表示，其中redisDb结构的dict字典保存了数据库中的所有键值对，把这个字典成为键空间</p><ul><li>键空间的键也就是数据库的键，每个键都是一个字符串对象</li><li>键空间的值也就是数据库的值，每个值可以是五种对象的任意一种Redis对象</li></ul></li><li><p>过期键的删除策略</p><p>redis服务器使用的是惰性删除和定期删除策略</p><ul><li><p>惰性删除策略的实现</p><p>过期键的惰性删除策略由db.c&#x2F;expireIfNeeded函数实现，所有读写数据库的Redis命令在执行之前都会调用该函数对输入键进行检查</p><ul><li>如果输入键已经过期，那么expireIfNeeded函数将输入键从数据库中删除</li><li>如果输入键未过期，那么函数不做动作</li></ul></li><li><p>定期删除策略的实现</p><p>过期键的定期删除策略由redis.c&#x2F;activeExpireCycle函数实现，每当Redis的服务器周期性操作redis.c&#x2F;serverCron函数执行时，activeExpireCycle函数就会被调用，在规定的时间内分多次便利服务器中的各个数据库，从数据库的expires字典中随机检查一部分键的过期时间并删除已过期的</p></li></ul></li><li><p>AOF、RDB和复制功能对过期键的处理</p><ul><li><p>RDB</p><ul><li><p>写入</p><p>创建新的RDB文件时，已过期的键不会被保存到新创建的RDB文件中</p></li><li><p>载入</p><ul><li>主服务器运行 ：过期键对载入RDB文件的主服务器不会造成影响</li><li>从服务器运行：所有键都会被载入到数据库中。不过由于主从服务器在进行数据同步时从服务器的数据库会被清空，因此该操作一般不会产生影响</li></ul></li></ul></li><li><p>AOF</p><ul><li><p>写入</p><p>当服务器以AOF持久化模式运行时，如果库中的某个键已经过期，但还未被惰性&#x2F;定期删除，AOF不会做任何特殊处理，当改键被惰性&#x2F;定期删除时，会向AOF文件追加一条DEL命令</p></li><li><p>重写</p><p>在进行AOF重写的过程中，已过期的键不会被保存到重写的AOF文件中</p></li></ul></li><li><p>复制</p><p>复制模式下，从服务器的过期键删除动作由主服务器控制，通过这种方式保证主从的一致性</p><ul><li>主服务器删除一个过期键后会显示的向所有从服务器发送DEL命令</li><li>从服务器只有在接到主服务器的DEL命令后才去删除过期键</li></ul></li></ul></li><li><p>RDB的自动保存条件</p><p>服务器的saveparams数组存储的时RDB的自动保存条件，最近XX秒内进行了XX次修改。</p><p>为了支持上述操作，服务器状态维持了一个dirty计数器和lastsave属性</p><ul><li>dirty计数器记录距离上次成功执行SAVA&#x2F;BGSAVE命令后服务器对数据库进行了几次修改</li><li>lastsave属性记录服务器上一次成功执行SAVE&#x2F;BGSAVE命令的时间</li></ul></li><li><p>AOF持久化</p><ul><li><p>AOF持久化的实现</p><ul><li><p>命令追加</p><p>服务器执行完一个写命令后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。</p></li><li><p>文件写入</p><p>服务器每次结束一个事件循环之前，都会调用flushAppendOnlyFile函数考虑是否将aof_buf缓冲区的内容写入和保存到AOF文件里面</p><p>flushAppendOnlyFile函数的行为由服务器配置的appendfysnc选项的值来决定</p><ul><li>Always: 服务器在每个事件循环都将aof_buf缓冲区中的所有内容写入到AOF文件并同步AOF文件</li><li>Everysec: 服务器在每个事件循环都将aof_buf缓冲区的所有内容写入到AOF文件并每隔1s在子线程对AOF文件进行同步</li><li>no: 服务器在每个事件循环都将aof_buf缓冲区的所有内容写入到AOF文件 由操作系统决定何时同步AOF文件</li></ul></li><li><p>文件同步</p></li></ul></li><li><p>AOF的载入与数据还原</p><ul><li><p>创建一个不带链接的伪客户端</p><p>因为Redis命令只能在客户端上下文执行</p></li><li><p>从AOF文件中分析并读取一条写命令</p></li><li><p>使用伪客户端执行被读出的写命令</p></li><li><p>重复步骤2和3</p></li></ul></li><li><p>AOF重写</p><ul><li>重写不需要对现有的AOF进行任何读取分析操作，重写是通过读取当前服务器的数据库状态来实现</li><li>重写在处理列表、哈希表、集合、有序集合这四种会有多个元素的键的时候，会检查元素数量，如果元素数量过长(当前版本是64)则会使用多条命令来记录键的值</li><li>Redis使用子进程来进行AOF重写，而为了避免数据不一致的问题，redis设置了AOF重写缓冲区，在服务器创建子进程用于重写后，redis服务器执行完一个写命令后会将该命令发送给AOF缓冲区和AOF重写缓冲区</li><li>重写结束后会向父进程发送信号，父进程在接到该信号后会调用信号处理函数<ul><li>将AOF重写缓冲区的内容写入到新的AOF文件</li><li>原子的覆盖现有AOF文件</li></ul></li><li>整个AOF后台重写过程，只有信号处理函数执行时会对父进程造成阻塞</li></ul></li></ul></li><li><p>Redis服务器时一个事件驱动程序，服务器需要处理以下两类事件</p><ul><li><p>文件事件</p><ul><li><p>文件事件处理器构成</p><ul><li><p>套接字</p><p>每当一个套接字准备好执行连接、应答、写入、读取、关闭等操作时会产生一个文件事件</p></li><li><p>I&#x2F;O多路复用程序</p><p>监听多个套接字并向文件事件分派器传送产生了事件的套件字</p></li><li><p>文件事件分派器</p><p>接受I&#x2F;O多路复用程序传来的套接字，并根据套接字产生的事件的类型调用相应的事件处理器</p></li><li><p>事件处理器</p></li></ul></li></ul></li><li><p>时间事件</p></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
      <category>Redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Redis</tag>
      
      <tag>读书笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>尝试解读一下helpGC</title>
    <link href="/2019/09/10/%E5%B0%9D%E8%AF%95%E8%A7%A3%E8%AF%BB%E4%B8%80%E4%B8%8BhelpGC/"/>
    <url>/2019/09/10/%E5%B0%9D%E8%AF%95%E8%A7%A3%E8%AF%BB%E4%B8%80%E4%B8%8BhelpGC/</url>
    
    <content type="html"><![CDATA[<p>在阅读JUC源码的时候，时不时能看到&#x2F;&#x2F;help GC这样的注释</p><span id="more"></span><p><img src="http://pwxc1xwdv.bkt.clouddn.com/blog-helpGC.png" alt="blog-helpGC"></p><p>起初读到这里就在思考，怎么就help GC了？我就一个赋值操作就可以help GC？怎么个help方法，素质三连之后发现并没有啥想法也就不了了之了。</p><p>之后，当我重读《深入理解Java虚拟机》的时候，当读到GC Roots节点的时候回想到了这个help GC的问题，思考会不会是因为GC Roots的原因呢？</p><p>相信大家都知道GC Roots也知道什么对象可以做为GC Roots</p><ul><li>虚拟机栈中引用的对象</li><li>方法区中常量引用的对象</li><li>方法区中静态属性引用的变量</li><li>本地方法栈中native方法引用的对象</li></ul><p>反正我最开始在看到这里的时候就是小笔一划，小圈一画也就直接往下继续看了，理解全靠死记硬背。</p><p>这里拿常量举例来说，如果它不作为GC Roots的话，那么就需要有一个更上层的GC Roots来指向它，那么这个更上层的节点又会是谁呢？想了想好像找不出来，反证法也得出常量需要是GC Roots节点。</p><p>再来说说help GC，现在想一想，栈中对象的生命周期和该方法的生命周期一样长，而常量和静态属性则在类加载过程的“准备”阶段就已经加载进JVM中，其生命周期和类的生命周期一样长应该是整个JVM期间，native方法不知道但猜测应该是和常量&#x2F;静态属性一样。既然说常量的生命周期和类的生命周期一样长，那么常量所引用的对象不使用后如果不显示的置NULL，岂不造成内存泄漏？想想似乎ThreadLocalMap中ThreadLocal设为弱引用好像也是基于此。</p><p>而上文中的示例，栈中引用的对象如果不显示的塞NULL值，那么在整个方法的运行过程中其一直存在，然后eden区就满了，显示的塞NULL后在GC过程中由于该节点是GC Roots节点，那么很快就会被标记到既而成功清除</p><p>而后在继续度娘的过程中发现了<a href="https://www.jianshu.com/p/4a1080373096?mType=Group&from=androidqq">这样一篇文章</a>，顿时发现实践是检验真理的唯一标准啊，膜拜大佬。</p><p>其实到这里，通过超链的文章已经证实了确实是有help GC，但是至于究竟怎么个help法还是不是特别的透彻，不过这正是学习的乐趣不是吗？</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>kafka分区一致性的思考</title>
    <link href="/2019/09/09/kafka%E5%88%86%E5%8C%BA%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%80%9D%E8%80%83/"/>
    <url>/2019/09/09/kafka%E5%88%86%E5%8C%BA%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%80%9D%E8%80%83/</url>
    
    <content type="html"><![CDATA[<p>在学习kafka的过程中，相信都听过一个概念<strong>“kafka不能保证消息整体的一致性，只能保证分区内的一致性“</strong>。其原因很简单当时看书的时候看到这里就觉得嗯嗯，是这么个道理，然后就接着往下看了。</p><p>后来在发送消息的API中，我以为发个消息，参数里就传topic和value就足够了，往指定topic里发value嘛，但是在代码里，发现除了这两个参数外，还有key这个参数，研讨一番后知道如果key不为null，计算得到的分区号会是所有分区中的任意一个（对key进行hash运算，相同hash的入同一分区），如果key为null，那么计算得到的分区号仅为可用分区中的任意一个。kafka的producer分区策略可以阅读DefaultPartitioner#partition方法</p><span id="more"></span><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">partition</span><span class="hljs-params">(String topic, Object key, <span class="hljs-type">byte</span>[] keyBytes, Object value, <span class="hljs-type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;<br>    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);<br>    <span class="hljs-type">int</span> <span class="hljs-variable">numPartitions</span> <span class="hljs-operator">=</span> partitions.size();<br>    <span class="hljs-keyword">if</span> (keyBytes == <span class="hljs-literal">null</span>) &#123; <span class="hljs-comment">// 未指定key</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">nextValue</span> <span class="hljs-operator">=</span> nextValue(topic);<br>        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);<span class="hljs-comment">// 得到所有可用分区</span><br>        <span class="hljs-keyword">if</span> (availablePartitions.size() &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">part</span> <span class="hljs-operator">=</span> Utils.toPositive(nextValue) % availablePartitions.size();<br>            <span class="hljs-keyword">return</span> availablePartitions.get(part).partition();<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// no partitions are available, give a non-available partition</span><br>            <span class="hljs-keyword">return</span> Utils.toPositive(nextValue) % numPartitions;<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// hash the keyBytes to choose a partition</span><br>        <span class="hljs-keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>以及nextValue方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">nextValue</span><span class="hljs-params">(String topic)</span> &#123;<br>    <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">counter</span> <span class="hljs-operator">=</span> topicCounterMap.get(topic);<br>    <span class="hljs-keyword">if</span> (<span class="hljs-literal">null</span> == counter) &#123;<br>        counter = <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>(ThreadLocalRandom.current().nextInt());<br>        <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">currentCounter</span> <span class="hljs-operator">=</span> topicCounterMap.putIfAbsent(topic, counter);<br>        <span class="hljs-keyword">if</span> (currentCounter != <span class="hljs-literal">null</span>) &#123;<br>            counter = currentCounter;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> counter.getAndIncrement();<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码大概意思也不难读懂，了解之后得出一个结论，key这个参数就是在发送消息的时候用来指定<strong>消息发往哪个分区的</strong></p><p>至此，得出了两个结论，但是当时并没有发散去思考问题，其实仔细想想，这两个概念还是有一定关联关系的。下面通过一个demo来分析一下。</p><p>后来的某一天，我们接了这样一个消息，这个消息的的内容是mysql的binlog，就是通过canal来解析mysql的binlog并将解析出来的DML和DDL写入kafka。</p><p>我当时通过<code>bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic TOPIC --describe</code>命令看了一下这个topic的详情，发现它的分区数量PartitionCount &#x3D; 1，当时很不理解为什么要把分区数量设为1，这样岂不是对于一个消费者组而言只有一个消费者在消费数据吗？不过由于开发这段功能的“前辈”已经离职了，所以也就不了了之了，一个分区就一个分区呗，我咸吃萝卜淡操着那个心干嘛。</p><p>后来，当我重读《深入理解Kafka：核心设计与实践原理》这本书的时候，再看到“kafka不能保证消息整体的一致性，只能保证分区内的一致性”这个概念的时候，突然想到了这个示例，突然间意识到原来当时那个topic的partitionCount &#x3D; 1 是有其业务意义的，因为消息的是表的DML语句，其对于顺序的要求是很高的，先Insert再Update和先Update再Insert这就有可能产生两种数据，如果这里建立了多个分区，一致性就得不到保障。当想通这个道理的时候不禁觉得前辈到底是前辈，这里确实只能建一个分区。</p><p>再后来，当我看到producer的key这个参数的时候，再回想这个示例不禁发现，真的只能建一个分区吗？kafka既然是一个成熟的中间件了，对于这种需要保证消息一致性的解决方案就是只能是建一个分区吗？显然，kafka留下了key这个参数用来解决这个问题，在该业务上，完全可以将同一张表的DML&#x2F;DDL用一个key来映射，不同的表使用不同的key，这样就完美解决了该问题，其分区也就可以根据情况来创建多个了。类比到其他业务线上比如订单系统中相同订单号的消息使用同一topic来send。想到这里，emmm，“前辈”确实只是个“前辈”。</p><p>至此，通过一个样例，将kafka的两个概念串联了起来，不禁觉得这些看起来很easy的概念，如果面试的时候面试官单问任何一个都可以侃侃而谈的概念，如果多思考，多问为什么，还是可以得到很多不一样的心得与体会的。学习的乐趣大体在于此吧。</p>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
      <category>kafka</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
